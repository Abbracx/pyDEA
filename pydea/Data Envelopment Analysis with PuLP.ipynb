{
 "metadata": {
  "name": "",
  "signature": "sha256:5811255413e5ff2da20616bfddb667ce4397cd0589878268473b8c250f1f6dbd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#A data envelopment analysis module using PuLP\n",
      "\n",
      "###DEA\n",
      "It is most useful when a comparison is sought against \"best practices\" where the analyst doesn't\n",
      "want the frequency of poorly run operations to affect the analysis. DEA has been applied in\n",
      "many situations such as: health care (hospitals, doctors), education (schools, universities), banks,\n",
      "manufacturing, benchmarking, management evaluation, fast food restaurants, and retail stores.\n",
      "The analyzed data sets vary in size. Some analysts work on problems with as few as 15 or 20\n",
      "DMUs while others are tackling problems with over 10,000 DMUs.\n",
      "\n",
      "###[Strengths and limitations](http://mat.gsia.cmu.edu/classes/QUANT/NOTES/chap12.pdf)\n",
      "As the earlier list of applications suggests, DEA can be a powerful tool when used wisely. A few of\n",
      "the characteristics that make it powerful are:\n",
      "- DEA can handle multiple input and multiple output models.\n",
      "- It doesn't require an assumption of a functional form relating inputs to outputs.\n",
      "- DMUs are directly compared against a peer or combination of peers.\n",
      "- Inputs and outputs can have very different units. For example, X1 could be in units of lives\n",
      "saved and X2 could be in units of dollars without requiring an a priori tradeof between the\n",
      "two.\n",
      "\n",
      "The same characteristics that make DEA a powerful tool can also create problems. An analyst\n",
      "should keep these limitations in mind when choosing whether or not to use DEA.\n",
      "- Since DEA is an extreme point technique, noise (even symmetrical noise with zero mean)\n",
      "such as measurement error can cause significant problems.\n",
      "- DEA is good at estimating \"relative\" efficiency of a DMU but it converges very slowly to\n",
      "\"absolute\" efficiency. In other words, it can tell you how well you are doing compared to your\n",
      "peers but not compared to a \"theoretical maximum.\"\n",
      "- Since DEA is a nonparametric technique, statistical hypothesis tests are difficult and are the\n",
      "focus of ongoing research.\n",
      "- Since a standard formulation of DEA creates a separate linear program for each DMU, large\n",
      "problems can be computationally intensive.\n",
      "\n",
      "\n",
      "###References\n",
      "\n",
      "- [PuLP](http://www.coin-or.org/PuLP/pulp.html)\n",
      "- [Python classes docs](https://docs.python.org/2/tutorial/classes.html) and [hints for class design](http://stackoverflow.com/questions/4203163/how-do-i-design-a-class-in-python)\n",
      "- [Weight restrictions in DEA](http://www.wbs.ac.uk/downloads/working_papers/352.pdf)\n",
      "- [Overview of DEA](http://www.nhh.no/Files/Filer/institutter/for/seminars/accounting_management_science/2007_spring/300507.pdf)\n",
      "- [NZ Post example](https://secure.orsnz.org.nz/conf45/program/Papers/ORSNZ2010_Priddey.pdf)\n",
      "- [Non-discretionary inputs in healthcare](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=952629)\n",
      "- [Non-discretionary inputs](https://www.nhh.no/Admin/Public/Download.aspx?file=Files%2FFiler%2Finstitutter%2Ffor%2Fseminars%2Faccounting_management_science%2F2007_spring%2F300507-1.pdf)\n",
      "- [DEA conference proceedings](http://deazone.com/en/wp-content/uploads/2014/05/DEA2013-Proceedings.pdf)\n",
      "- [DEAP programme notes](http://www.owlnet.rice.edu/~econ380/DEAP.PDF)\n",
      "- [DEA on panel data](http://competitionpolicy.ac.uk/documents/107435/107587/1.114399!ccp09-6.pdf)\n",
      "- [Data preparation for DEA](www.clarku.edu/~jsarkis/sarkischapter.doc)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#The linear programming problem"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%latex\n",
      "An input-oriented DEA model with constant returns to scale is solved with the following LP model:\n",
      "\n",
      "\\begin{equation}\n",
      "\\max e_{j_0} = \\sum_r u_r y_{rj_0} - \\mu_0\n",
      "\\end{equation}\n",
      "\n",
      "subject to\n",
      "\n",
      "\\begin{aligned}\n",
      "\\sum_i v_i x_{ij_0} &= 1 \\\\\n",
      "\\sum_r u_r y_{rj} - \\sum_i v_i x_{ij} - \\mu_0 &\\leq 0, \\quad j \\in 1, 2, \\ldots, n \\\\\n",
      "u_r, v_i &\\geq \\varepsilon\n",
      "\\end{aligned}\n",
      "\n",
      "where\n",
      "\n",
      "\\begin{aligned}\n",
      "x_{ij} &= \\mbox{quantity of input } i \\mbox{ for unit } j \\\\\n",
      "v_{i} &= \\mbox{weight attached to input } i \\\\\n",
      "y_{ij} &= \\mbox{quantity of output } r \\mbox{ for unit } j \\\\\n",
      "u_{i} &= \\mbox{weight attached to output } r \\\\\n",
      "e_{j_0} &= \\mbox{efficiency score} \\\\\n",
      "\\mu_0 &= \\mbox{VRS parameter} \\\\\n",
      "j_0 &= \\mbox{DMU under analysis} \\\\\n",
      "\\end{aligned}\n",
      "\n",
      "Input and output quantities are fixed by the data, weights are the decision variables and the efficiency score is the output."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "latex": [
        "An input-oriented DEA model with constant returns to scale is solved with the following LP model:\n",
        "\n",
        "\\begin{equation}\n",
        "\\max e_{j_0} = \\sum_r u_r y_{rj_0} - \\mu_0\n",
        "\\end{equation}\n",
        "\n",
        "subject to\n",
        "\n",
        "\\begin{aligned}\n",
        "\\sum_i v_i x_{ij_0} &= 1 \\\\\n",
        "\\sum_r u_r y_{rj} - \\sum_i v_i x_{ij} - \\mu_0 &\\leq 0, \\quad j \\in 1, 2, \\ldots, n \\\\\n",
        "u_r, v_i &\\geq \\varepsilon\n",
        "\\end{aligned}\n",
        "\n",
        "where\n",
        "\n",
        "\\begin{aligned}\n",
        "x_{ij} &= \\mbox{quantity of input } i \\mbox{ for unit } j \\\\\n",
        "v_{i} &= \\mbox{weight attached to input } i \\\\\n",
        "y_{ij} &= \\mbox{quantity of output } r \\mbox{ for unit } j \\\\\n",
        "u_{i} &= \\mbox{weight attached to output } r \\\\\n",
        "e_{j_0} &= \\mbox{efficiency score} \\\\\n",
        "\\mu_0 &= \\mbox{VRS parameter} \\\\\n",
        "j_0 &= \\mbox{DMU under analysis} \\\\\n",
        "\\end{aligned}\n",
        "\n",
        "Input and output quantities are fixed by the data, weights are the decision variables and the efficiency score is the output."
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<IPython.core.display.Latex at 0x49fce80>"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Data below is from [this paper](http://www.wbs.ac.uk/downloads/working_papers/352.pdf) and is used to validate the outputs of the DEA routine.\n",
      "\n",
      "Output should be:\n",
      "\n",
      "    DMU u1       u2     u3     v1     v2     efficiency\n",
      "    A   0.0006   0      0.0014 0.01   0      96.20%\n",
      "    B   0        0.004  0.0024 0.0083 0      79.88%\n",
      "    C   0        0.0096 0.0057 0.02   0      100.00%\n",
      "    D   0        0.0068 0.0056 0.0121 0.011  100.00%\n",
      "    E   0        0.0051 0      0.0102 0      100.00%\n",
      "    F   0.0009   0      0.0081 0.0021 0.0699 100.00%"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file tests/dea_tests.py\n",
      "\n",
      "import nose\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "from pydea.dea import DEA\n",
      "from numpy.testing import assert_array_equal\n",
      "\n",
      "\n",
      "class TestDEA():\n",
      "    @classmethod\n",
      "    def setup_class(cls):\n",
      "        \"\"\"This method is run once for each class before any tests are run\"\"\"\n",
      "        cls.inputs = pd.DataFrame([[100, 70], [120, 123], [50, 20], [67, 17], [98, 20], [76, 12]])\n",
      "        cls.outputs = pd.DataFrame([[1540, 154, 59], [1408, 186, 23 ], [690, 59, 76], [674, 73, 90], [1686, 197, 12], [982, 63, 15]])\n",
      "        \n",
      "    def setUp(self):\n",
      "        \"\"\"This method is run once before _each_ test method is executed\"\"\"\n",
      "        pass\n",
      "        \n",
      "    def teardown(self):\n",
      "        \"\"\"This method is run once after _each_ test method is executed\"\"\"\n",
      "        pass\n",
      "    \n",
      "    def test_init_attributes(self):\n",
      "        \"\"\"Test attributes of init\"\"\"\n",
      "        myprob = DEA(self.inputs, self.outputs)\n",
      "        np.testing.assert_array_equal(myprob.inputs, self.inputs)\n",
      "        np.testing.assert_array_equal(myprob.outputs, self.outputs)\n",
      "        nose.tools.assert_equal(myprob.J, 6)\n",
      "        nose.tools.assert_equal(myprob.I, 2)\n",
      "        nose.tools.assert_equal(myprob.R, 3)\n",
      "        \n",
      "    @nose.tools.raises(AssertionError)\n",
      "    def test_init_asserts(self):\n",
      "        \"\"\"Test asserts of init\"\"\"\n",
      "        myprob = DEA(pd.DataFrame([[100]]), pd.DataFrame([[1], [2]]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting tests/dea_tests.py\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Run nosetests"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!nosetests"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "..\n",
        "----------------------------------------------------------------------\n",
        "Ran 2 tests in 0.038s\n",
        "\n",
        "OK\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Main programme"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%file dea.py\n",
      "# The core DEA class, setting up and solving the linear programming problems using PuLP.\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import pulp\n",
      "\n",
      "\n",
      "class DEA:\n",
      "    \"\"\"\n",
      "    A container for the elements of a data envelopment analysis problem. Sets up the linear programmes and solves them with pulp.\n",
      "    \n",
      "    Requires:\n",
      "    \n",
      "        inputs: a pandas dataframe of the inputs to the DMUs\n",
      "        outputs: a pandas dataframe of the outputs from the DMUs\n",
      "        kind: 'VRS' or 'CRS'\n",
      "        in_weights: the lower-bound weight restriction to apply to all inputs to all DMUs (default is 0)\n",
      "        out_weights: the lower-bound weight restriction to apply to all outputs to all DMUs (default is 0)\n",
      "    \n",
      "    \"\"\"\n",
      "\n",
      "    \n",
      "    def __init__(self, inputs, outputs, returns='CRS', in_weights=0, out_weights=0):\n",
      "        \"\"\"\n",
      "        Set up the DMUs' problems, ready to solve.\n",
      "        \n",
      "        \"\"\"\n",
      "        self.inputs = self._to_dataframe(inputs)\n",
      "        self.outputs = self._to_dataframe(outputs)\n",
      "        self.returns = returns\n",
      "               \n",
      "        self.J, self.I = self.inputs.shape  # no of firms, inputs\n",
      "        _, self.R = self.outputs.shape  # no of outputs\n",
      "        self._i = np.arange(self.I)  # inputs\n",
      "        self._r = np.arange(self.R)  # outputs\n",
      "        self._j = np.arange(self.J)  # DMUs\n",
      "        \n",
      "        self._in_weights = in_weights\n",
      "        self._out_weights = out_weights\n",
      "\n",
      "        self.dmus = self._create_problems()  # creates dictionary of pulp.LpProblem objects for the DMUs\n",
      "\n",
      "    \n",
      "    def _to_dataframe(self, indata):\n",
      "        \"\"\"\n",
      "        Indexers require input to be a dataframe but the user may pass a series. Check and cast series to dataframes.\n",
      "        \n",
      "        \"\"\"\n",
      "        \n",
      "        if type(indata) == pd.core.frame.DataFrame:\n",
      "            return indata\n",
      "        elif type(indata) == pd.core.series.Series:\n",
      "            return pd.DataFrame(indata)\n",
      "        else:\n",
      "            raise TypeError(\"Input data is not a valid pandas DataFrame or Series.\")\n",
      "        \n",
      "    \n",
      "    def _create_problems(self):\n",
      "        \"\"\"\n",
      "        Iterate over the inputs and create a dictionary of LP problems, one for each DMU.\n",
      "        \n",
      "        \"\"\"\n",
      "        \n",
      "        dmu_dict = {}\n",
      "        for j0 in self._j:\n",
      "            dmu_dict[j0] = self._make_problem(j0)\n",
      "        return dmu_dict\n",
      " \n",
      "    \n",
      "    def _make_problem(self, j0):\n",
      "        \"\"\"\n",
      "        Create a pulp.LpProblem for a DMU.\n",
      "        \n",
      "        \"\"\"\n",
      "        \n",
      "        ##Set up pulp\n",
      "        prob = pulp.LpProblem(\"\".join([\"DMU_\", str(j0)]), pulp.LpMaximize)\n",
      "        self.inputWeights = pulp.LpVariable.dicts(\"inputWeight\", (self._j, self._i), lowBound=self._in_weights)\n",
      "        self.outputWeights = pulp.LpVariable.dicts(\"outputWeight\", (self._j, self._r), lowBound=self._out_weights)\n",
      "                \n",
      "        ##Set returns to scale\n",
      "        if self.returns == \"CRS\":\n",
      "            w = 0\n",
      "        elif self.returns == \"VRS\":\n",
      "            w = pulp.LpVariable.dicts(\"w\", (self._j, self._r))\n",
      "        else:\n",
      "            raise Exception(ValueError)\n",
      "\n",
      "        ##Set up objective function\n",
      "        prob += pulp.LpAffineExpression([(self.outputWeights[j0][r1], self.outputs.values[j0][r1]) for r1 in self._r]) - w\n",
      "\n",
      "        ##Set up constraints\n",
      "        prob += pulp.LpAffineExpression([(self.inputWeights[j0][i1], self.inputs.values[j0][i1]) for i1 in self._i]) == 1, \"Norm_constraint\"\n",
      "        for j1 in self._j:\n",
      "            prob += self._dmu_constraint(j0, j1)  - w <= 0, \"\".join([\"DMU_constraint_\", str(j1)])\n",
      "        return prob\n",
      "    \n",
      "    \n",
      "    def _dmu_constraint(self, j0, j1):\n",
      "        \"\"\"\n",
      "        Calculate and return the DMU constraint for a single DMU's LP problem.\n",
      "        \n",
      "        \"\"\"\n",
      "        \n",
      "        eOut = pulp.LpAffineExpression([(self.outputWeights[j0][r1], self.outputs.values[j1][r1]) for r1 in self._r])\n",
      "        eIn = pulp.LpAffineExpression([(self.inputWeights[j0][i1], self.inputs.values[j1][i1]) for i1 in self._i])\n",
      "        return eOut - eIn     \n",
      "\n",
      "    \n",
      "    def _solver(self):\n",
      "        \"\"\"\n",
      "        Iterate over the dictionary of DMUs' problems, solve them, and collate the results into a pandas dataframe.\n",
      "        \n",
      "        \"\"\"\n",
      "        \n",
      "        sol_status = {}\n",
      "        sol_results = {}\n",
      "        sol_weights = {}\n",
      "        sol_efficiency = {}\n",
      "        for ind, problem in self.dmus.iteritems():\n",
      "            problem.solve()\n",
      "            sol_status[ind] = pulp.LpStatus[problem.status]\n",
      "            sol_weights[ind] = {}\n",
      "            for v in problem.variables():\n",
      "                sol_weights[ind][v.name] = v.varValue\n",
      "            sol_efficiency[ind] = pulp.value(problem.objective)\n",
      "        return pd.DataFrame.from_dict({'Status': sol_status, 'Efficiency': sol_efficiency, 'Weights': sol_weights})\n",
      "        \n",
      "    \n",
      "    def solve(self):\n",
      "        self.results = self._solver()\n",
      "        self.results.index = self.inputs.index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting dea.py\n"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%file tools.py\n",
      "# Tools for working with the solved DEA objects.\n",
      "\n",
      "\n",
      "def env_corr(dea_obj, env_vars):\n",
      "    \"\"\"\n",
      "    Determine correlations with environmental/non-discretionary variables using a logit regression. Tobit will be implemented when available upstream in statsmodels.\n",
      "    \n",
      "    Takes:\n",
      "        dea_obj: The solved DEA instance.\n",
      "        env_vars: A pandas dataframe of \n",
      "        \n",
      "    Returns:\n",
      "        corr_mod: the statsmodels' model instance containing the inputs and results from the logit model.\n",
      "    \n",
      "    Note that there can be no spaces in the variables' names.\n",
      "    \"\"\"\n",
      "    \n",
      "    print \"A logit regression will be used. A censored regression with a Tobit model would be more correct but it is not yet provided by statsmodels.\\n\"\n",
      "    \n",
      "    import statsmodels.api as sm\n",
      "    from statsmodels.formula.api import logit\n",
      "    \n",
      "    corr_data = env_vars.join(dea_obj.results['Efficiency'])\n",
      "    corr_mod = logit(\"Efficiency ~ \" + \" + \".join(env_vars.columns), corr_data).fit()\n",
      "    \n",
      "    mfx = corr_mod.get_margeff()\n",
      "    print mfx.summary()\n",
      "    \n",
      "    return corr_mod\n",
      "\n",
      "\n",
      "def normalise_df(df):\n",
      "    dfnorm = pd.DataFrame(index=df.index)\n",
      "    for ind, ser in df.iteritems():\n",
      "        dfnorm[ind] = (ser - ser.mean()) / ser.std()\n",
      "    return dfnorm\n",
      "\n",
      "\n",
      "def deaPCA(df, allres=False, normalise=False, plot=True):\n",
      "    \"\"\"\n",
      "    Extract principal components from pandas dataframe and shift distribution so that all values are strictly positive, as required for DEA.\n",
      "    \n",
      "    Takes:\n",
      "        df: A dataframe of series to run the PCA on.\n",
      "        allres: Boolean. Set True if you would like to get the PCA object returned instead of the transformed data. This can be useful if you wish to use the entire results of the PCA.\n",
      "        normalise: Boolean. Set True to normalise the series to a z-score before transforming.\n",
      "        plot: Should the function display a plot of the variance explained?\n",
      "    \"\"\"\n",
      "    \n",
      "    from sklearn.decomposition import PCA as sklearnPCA\n",
      "\n",
      "    if normalise:\n",
      "        df = normalise_df(df)\n",
      "    \n",
      "    indat_pca = sklearnPCA()\n",
      "    indat_transf = pd.DataFrame(indat_pca.fit_transform(df.values), index=df.index)\n",
      "\n",
      "    for ser, vals in indat_transf.iteritems():\n",
      "        if vals.min() <=0:\n",
      "            indat_transf[ser] = vals + np.abs(vals.min()) + 1\n",
      "   \n",
      "    if plot:\n",
      "        fig1, ax1 = plt.subplots()\n",
      "        ax1.plot(np.array(indat_pca.explained_variance_ratio_).cumsum())\n",
      "        ax1.bar(np.arange(0.1, len(indat_pca.explained_variance_ratio_), 1), np.array(indat_pca.explained_variance_ratio_))\n",
      "        ax1.set_title('Variance explained by each principal component')\n",
      "        ax1.set_xlim(right=len(indat_pca.explained_variance_ratio_))\n",
      "        ax1.set_ylim(top=1)\n",
      "\n",
      "    if allres:\n",
      "        return indat_pca\n",
      "    else:\n",
      "        return indat_transf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting tools.py\n"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Scratchpad\n",
      "\n",
      "This and the profiling cells depend on the above being run without writing to file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "inputs = pd.DataFrame([[100, 70], [120, 123], [50, 20], [67, 17], [98, 20], [76, 12]], columns=['Teaching staff', 'Research staff'])\n",
      "outputs = pd.DataFrame([[1540, 154, 59], [1408, 186, 23 ], [690, 59, 76], [674, 73, 90], [1686, 197, 12], [982, 63, 15]], columns=['Undergraduates', 'Masters', 'Publications'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(inputs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 63,
       "text": [
        "pandas.core.frame.DataFrame"
       ]
      }
     ],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(outputs['Undergraduates'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 64,
       "text": [
        "pandas.core.series.Series"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "myprob = DEA(inputs, outputs.Undergraduates, returns='VRS')\n",
      "myprob.solve()\n",
      "print myprob.results[['Status', 'Efficiency']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<class 'pandas.core.frame.DataFrame'>\n",
        "<class 'pandas.core.series.Series'>\n",
        "    Status  Efficiency\n",
        "0  Optimal    0.909639\n",
        "1  Optimal    0.705020\n",
        "2  Optimal    1.000000\n",
        "3  Optimal    0.940695\n",
        "4  Optimal    1.000000\n",
        "5  Optimal    1.000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 575 ms\n"
       ]
      }
     ],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Profiling"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cProfile, pstats\n",
      "\n",
      "def runmake():\n",
      "    inputs = np.array([[100, 70], [120, 123], [50, 20], [67, 17], [98, 20], [76, 12]])\n",
      "    outputs = np.array([[1540, 154, 59], [1408, 186, 23 ], [690, 59, 76], [674, 73, 90], [1686, 197, 12], [982, 63, 15]])\n",
      "    return DEA(inputs, outputs, kind='VRS')\n",
      "\n",
      "dea_stats = cProfile.run(\"runmake()\", 'deastats')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p = pstats.Stats('deastats')\n",
      "p.strip_dirs().sort_stats('cumtime').print_stats(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tue Aug 26 11:05:25 2014    deastats\n",
        "\n",
        "         35543 function calls (34427 primitive calls) in 0.086 seconds\n",
        "\n",
        "   Ordered by: cumulative time\n",
        "   List reduced from 52 to 10 due to restriction <10>\n",
        "\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "        1    0.000    0.000    0.086    0.086 <string>:1(<module>)\n",
        "        1    0.000    0.000    0.086    0.086 <ipython-input-9-b8254aa31928>:3(runmake)\n",
        "        1    0.000    0.000    0.086    0.086 <ipython-input-2-7ee59da55d8f>:16(__init__)\n",
        "        1    0.000    0.000    0.086    0.086 <ipython-input-2-7ee59da55d8f>:31(_create_problems)\n",
        "        6    0.002    0.000    0.086    0.014 <ipython-input-2-7ee59da55d8f>:37(_make_problem)\n",
        "      246    0.003    0.000    0.040    0.000 pulp.py:532(__init__)\n",
        "      120    0.000    0.000    0.039    0.000 pulp.py:752(__sub__)\n",
        "      252    0.004    0.000    0.030    0.000 collections.py:38(__init__)\n",
        "      252    0.006    0.000    0.025    0.000 _abcoll.py:526(update)\n",
        "       36    0.000    0.000    0.025    0.001 pulp.py:811(__le__)\n",
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "<pstats.Stats instance at 0x0000000004AFECC8>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def runsolve():\n",
      "    inputs = np.array([[100, 70], [120, 123], [50, 20], [67, 17], [98, 20], [76, 12]])\n",
      "    outputs = np.array([[1540, 154, 59], [1408, 186, 23 ], [690, 59, 76], [674, 73, 90], [1686, 197, 12], [982, 63, 15]])\n",
      "    myprob = DEA(inputs, outputs, kind='VRS')\n",
      "    return myprob.solve()\n",
      "\n",
      "dea_stats2 = cProfile.run(\"runsolve()\", 'deastats2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "p2 = pstats.Stats('deastats2')\n",
      "p2.strip_dirs().sort_stats('cumtime').print_stats(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tue Aug 26 11:05:40 2014    deastats2\n",
        "\n",
        "         59509 function calls (58393 primitive calls) in 1.867 seconds\n",
        "\n",
        "   Ordered by: cumulative time\n",
        "   List reduced from 113 to 10 due to restriction <10>\n",
        "\n",
        "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
        "        1    0.000    0.000    1.867    1.867 <string>:1(<module>)\n",
        "        1    0.000    0.000    1.867    1.867 <ipython-input-13-8ef6b782dd4b>:1(runsolve)\n",
        "        1    0.000    0.000    1.779    1.779 <ipython-input-2-7ee59da55d8f>:65(solve)\n",
        "        6    0.000    0.000    1.775    0.296 pulp.py:1599(solve)\n",
        "        6    0.000    0.000    1.775    0.296 solvers.py:1281(actualSolve)\n",
        "        6    0.001    0.000    1.774    0.296 solvers.py:1289(solve_CBC)\n",
        "        6    0.000    0.000    1.428    0.238 subprocess.py:650(__init__)\n",
        "        6    0.000    0.000    1.427    0.238 subprocess.py:898(_execute_child)\n",
        "        6    1.426    0.238    1.426    0.238 {_subprocess.CreateProcess}\n",
        "        6    0.000    0.000    0.298    0.050 subprocess.py:992(wait)\n",
        "\n",
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<pstats.Stats instance at 0x0000000004AF77C8>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}